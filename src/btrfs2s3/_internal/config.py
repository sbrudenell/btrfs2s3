# btrfs2s3 - maintains a tree of differential backups in object storage.
#
# Copyright (C) 2024 Steven Brudenell and other contributors.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

"""Code for manipulating config for btrfs2s3."""

from __future__ import annotations

from collections import namedtuple
from typing import Any
from typing import cast
from typing import TYPE_CHECKING
from typing import TypedDict

from cfgv import Array
from cfgv import check_and
from cfgv import check_array
from cfgv import check_string
from cfgv import check_type
from cfgv import load_from_filename
from cfgv import Map
from cfgv import Optional
from cfgv import OptionalNoDefault
from cfgv import OptionalRecurse
from cfgv import Required
from cfgv import RequiredRecurse
from typing_extensions import NotRequired
from yaml import safe_load

from btrfs2s3._internal.cost import BYTES_ABBREV_TO_MULT
from btrfs2s3._internal.durations import Duration
from btrfs2s3._internal.preservation import Params

if TYPE_CHECKING:
    from os import PathLike


class Error(Exception):
    """The top-level class for exceptions generated by this module."""


class InvalidConfigError(Error):
    """An error for invalid config."""


def _check_preserve(v: Any) -> None:  # noqa: ANN401
    check_string(v)
    try:
        Params.parse(v)
    except ValueError as ex:
        msg = "Expected a valid schedule"
        raise InvalidConfigError(msg) from ex


def _check_bytes(v: Any) -> None:  # noqa: ANN401
    check_string(v)
    if v not in BYTES_ABBREV_TO_MULT:
        msg = f"Expected a bytes value ({'|'.join(BYTES_ABBREV_TO_MULT.keys())})"
        raise InvalidConfigError(msg)


def _check_nonzero_duration(v: Any) -> None:  # noqa: ANN401
    check_string(v)
    try:
        d = Duration(v)
    except ValueError as ex:
        msg = "Expected a valid ISO8601 duration"
        raise InvalidConfigError(msg) from ex
    if all(value == 0 for value in d.values()):
        msg = "Duration cannot be zero"
        raise InvalidConfigError(msg)


def _check_unit_duration(v: Any) -> None:  # noqa: ANN401
    _check_nonzero_duration(v)
    d = Duration(v)
    if list(d.values()) != [1]:
        msg = "Duration must be a single unit (P1M, PT1H, etc)"
        raise InvalidConfigError(msg)


def _check_single_item_duration(v: Any) -> None:  # noqa: ANN401
    _check_nonzero_duration(v)
    d = Duration(v)
    if len(d) != 1:
        msg = "Duration must have a single item (P1M, P30D, but not P1M1D)"
        raise InvalidConfigError(msg)


def _check_gt0(v: float) -> None:
    if v <= 0:
        msg = "Must be greater than 0"
        raise InvalidConfigError(msg)


def _apply_default_optional_recurse_no_default(self: Any, dct: dict[Any, Any]) -> None:  # noqa: ANN401
    if self.key in dct:
        RequiredRecurse.apply_default(self, dct)


# this is the same style used in cfgv
_OptionalRecurseNoDefault = namedtuple(  # noqa: PYI024
    "_OptionalRecurseNoDefault", ("key", "schema")
)
_OptionalRecurseNoDefault.check = OptionalRecurse.check  # type: ignore[attr-defined]
_OptionalRecurseNoDefault.check_fn = OptionalRecurse.check_fn  # type: ignore[attr-defined]
_OptionalRecurseNoDefault.apply_default = _apply_default_optional_recurse_no_default  # type: ignore[attr-defined]
_OptionalRecurseNoDefault.remove_default = OptionalRecurse.remove_default  # type: ignore[attr-defined]


class S3EndpointConfig(TypedDict):
    """A config dict for how to talk to an S3 endpoint."""

    aws_access_key_id: NotRequired[str]
    aws_secret_access_key: NotRequired[str]
    region_name: NotRequired[str]
    profile_name: NotRequired[str]
    verify: NotRequired[bool | str]
    endpoint_url: NotRequired[str]


_S3_ENDPOINT_SCHEMA = Map(
    "S3EndpointConfig",
    None,
    OptionalNoDefault("aws_access_key_id", check_string),
    OptionalNoDefault("aws_secret_access_key", check_string),
    OptionalNoDefault("region_name", check_string),
    OptionalNoDefault("profile_name", check_string),
    OptionalNoDefault("verify", check_type((bool, str), typename="bool or path")),
    OptionalNoDefault("endpoint_url", check_string),
)


class CostPerByteAndTimeConfig(TypedDict):
    cost: float
    per_bytes: str
    per_time: str


_COST_PER_BYTES_AND_TIME_SCHEMA = Map(
    "CostPerTimeConfig",
    None,
    Required("cost", check_and(check_type(float), _check_gt0)),
    Optional("per_bytes", _check_bytes, "GB"),
    Optional("per_time", _check_single_item_duration, "P1M"),
)


class S3StorageClassCostConfig(TypedDict):
    name: str
    storage: CostPerByteAndTimeConfig
    min_time: NotRequired[str]


_S3_STORAGE_CLASS_COST_SCHEMA = Map(
    "S3StorageClassCostConfig",
    "name",
    RequiredRecurse("storage", _COST_PER_BYTES_AND_TIME_SCHEMA),
    OptionalNoDefault("min_time", _check_nonzero_duration),
)


class S3CostsConfig(TypedDict):
    storage_classes: list[S3StorageClassCostConfig]
    storage_time_granularity: str
    billing_period: str


_S3_COSTS_SCHEMA = Map(
    "S3CostsConfig",
    None,
    RequiredRecurse(
        "storage_classes", Array(_S3_STORAGE_CLASS_COST_SCHEMA, allow_empty=False)
    ),
    Optional("storage_time_granularity", _check_unit_duration, "PT1H"),
    Optional("billing_period", _check_unit_duration, "P1M"),
)


class S3RemoteConfig(TypedDict):
    """A config dict for how to access an S3 remote."""

    bucket: str
    endpoint: NotRequired[S3EndpointConfig]
    costs: NotRequired[S3CostsConfig]


_S3_SCHEMA = Map(
    "S3RemoteConfig",
    None,
    Required("bucket", check_string),
    _OptionalRecurseNoDefault("endpoint", _S3_ENDPOINT_SCHEMA),
    _OptionalRecurseNoDefault("costs", _S3_COSTS_SCHEMA),
)


class RemoteConfig(TypedDict):
    """A config dict for how to access a remote."""

    id: str
    s3: NotRequired[S3RemoteConfig]


_REMOTE_SCHEMA = Map(
    "RemoteConfig",
    None,
    Required("id", check_string),
    RequiredRecurse("s3", _S3_SCHEMA),
)


class UploadToRemoteConfig(TypedDict):
    """A config dict for uploading a source to a remote."""

    id: str
    preserve: str
    pipe_through: NotRequired[list[list[str]]]


_UPLOAD_TO_REMOTE_SCHEMA = Map(
    "UploadToRemoteConfig",
    "id",
    Required("preserve", _check_preserve),
    OptionalNoDefault("pipe_through", check_array(check_array(check_string))),
)


class SourceConfig(TypedDict):
    """A config dict for a source."""

    path: str
    snapshots: str
    upload_to_remotes: list[UploadToRemoteConfig]


_SOURCE_SCHEMA = Map(
    "SourceConfig",
    "path",
    Required("path", check_string),
    Required("snapshots", check_string),
    RequiredRecurse(
        "upload_to_remotes", Array(_UPLOAD_TO_REMOTE_SCHEMA, allow_empty=False)
    ),
)


class Config(TypedDict):
    """The top-level config dict.

    This just matches the data as it's stored in config.yaml. We don't do any
    transformation up front (for example "preserve" values are just their
    strings, not Policy objects).
    """

    timezone: str
    sources: list[SourceConfig]
    remotes: list[RemoteConfig]


_SCHEMA = Map(
    "Config",
    None,
    Required("timezone", check_string),
    RequiredRecurse("sources", Array(_SOURCE_SCHEMA, allow_empty=False)),
    RequiredRecurse("remotes", Array(_REMOTE_SCHEMA, allow_empty=False)),
)


def load_from_path(path: str | PathLike[str]) -> Config:
    """Load config from a file path.

    This performs some basic syntactic validation on the config, to ensure it
    really conforms to the return type.

    Args:
        path: The path to the config.

    Returns:
        A Config instance.

    Raises:
        InvalidConfigError: If the config does not pass validation.
    """
    config = cast(
        "Config",
        load_from_filename(path, _SCHEMA, safe_load, exc_tp=InvalidConfigError),
    )

    remote_ids = {remote["id"] for remote in config["remotes"]}
    for source in config["sources"]:
        for upload_to_remote in source["upload_to_remotes"]:
            if upload_to_remote["id"] not in remote_ids:
                msg = (
                    f"remote id {upload_to_remote['id']!r} for source "
                    f"{source['path']!r} is not defined in the list of remotes"
                )
                raise InvalidConfigError(msg)

    return config
